
namespace intr {
 alignas(uint8_t) struct ssp_u8 {
  STX_MAKE_PINNED(ssp_u8)

  explicit constexpr ssp_u8(uint8_t initial) : ____value{initial} {}

  constexpr void store(uint8_t value, std::memory_order) { ____value = value; }

  constexpr uint8_t load(std::memory_order) const { return ____value; }

  constexpr bool compare_exchange_strong(uint8_t& expected, uint8_t target,
                                         std::memory_order, std::memory_order) {
    bool success = false;
    if (expected == ____value) {
      ____value = target;
      success = true;
    }

    expected = ____value;

    return success;
  }

 private:
  uint8_t ____value = 0;
};

alignas(uint8_t) struct smp_u8 {
  STX_MAKE_PINNED(smp_u8)

  explicit smp_u8(uint8_t initial) : ____value{initial} {}

  void store(uint8_t value, std::memory_order order) {
    ____value.store(value, order);
  }

  uint8_t load(std::memory_order order) const { return ____value.load(order); }

  bool compare_exchange_strong(uint8_t& expected, uint8_t target,
                               std::memory_order on_success,
                               std::memory_order on_fail) {
    return ____value.compare_exchange_strong(expected, target, on_success,
                                             on_fail);
  }

 private:
  std::atomic<uint8_t> ____value = 0;
};

alignas(uint64_t) struct ssp_u64 {
  STX_MAKE_PINNED(ssp_u64)

  explicit constexpr ssp_u64(uint64_t initial) : ____value{initial} {}

  constexpr uint64_t fetch_add(uint64_t add, std::memory_order order) {
    (void)order;
    uint64_t old_value = ____value;
    ____value += add;
    return old_value;
  }

  constexpr uint64_t fetch_sub(uint64_t sub, std::memory_order order) {
    (void)order;
    uint64_t old_value = ____value;
    ____value -= sub;
    return old_value;
  }

 private:
  uint64_t ____value = 0;
};

alignas(std::atomic<uint64_t>) struct smp_u64 {
  STX_MAKE_PINNED(smp_u64)

  explicit smp_u64(uint64_t initial) : ____value{initial} {}

  uint64_t fetch_add(uint64_t add, std::memory_order order) {
    return ____value.fetch_add(add, order);
  }

  uint64_t fetch_sub(uint64_t sub, std::memory_order order) {
    return ____value.fetch_sub(sub, order);
  }

 private:
  std::atomic<uint64_t> ____value;
};

template <typename Enum>
alignas(ssp_u8) struct ssp_u8_enum {
  static_assert(std::is_enum_v<Enum>);
  static_assert(std::is_same_v<std::underlying_type_t<Enum>, uint8_t>);

  explicit constexpr ssp_u8_enum(Enum intial)
      : ____impl{static_cast<uint8_t>(initial)} {}

  constexpr void store(Enum value, std::memory_order order) {
    return ____impl.store(value, order);
  }

  constexpr Enum load(std::memory_order order) const {
    return ____impl.load(order);
  }

  constexpr bool compare_exchange_strong(Enum& expected, Enum target,
                                         std::memory_order on_success,
                                         std::memory_order on_fail) {
    return ____impl.compare_exchange_strong(
        reinterpret_cast<uint8_t*>(expected), static_cast<uint8_t>(target),
        on_success, on_fail);
  }

  ssp_u8 ____impl;
};

template <typename Enum>
struct smp_u8_enum {
  static_assert(std::is_enum_v<Enum>);
  static_assert(std::is_same_v<std::underlying_type_t<Enum>, uint8_t>);

  explicit constexpr smp_u8_enum(Enum intial)
      : ____impl{static_cast<uint8_t>(initial)} {}

  constexpr void store(Enum value, std::memory_order order) {
    return ____impl.store(value, order);
  }

  constexpr Enum load(std::memory_order order) const {
    return ____impl.load(order);
  }

  constexpr bool compare_exchange_strong(Enum& expected, Enum target,
                                         std::memory_order on_success,
                                         std::memory_order on_fail) {
    return ____impl.compare_exchange_strong(
        reinterpret_cast<uint8_t*>(expected), static_cast<uint8_t>(target),
        on_success, on_fail);
  }

  smp_u8_enum ____impl;
};

};  // namespace intr


#include "stx/struct.h"

namespace stx {

/// thread-safe
///
///
/// RefCnt objects should be created in batches to avoid false
/// sharing issues
///
///
/// we assume the user is sharing data/instructions and their side effects via a
/// shared object shared across threads, so we perform acquire when performing
/// unref.
///
///
///
///
/// TODO(lamarrr): this should probably go to a separate directory and also be
/// used for the panic code.
///
///
// if the application is multi-threaded, the compiler can make more informed
// decisions about reference-counting.
struct SingleThreadedRefCount {
  STX_MAKE_PINNED(SingleThreadedRefCount)

  uint64_t ref_count;

  constexpr explicit SingleThreadedRefCount(uint64_t initial_ref_count)
      : ref_count{initial_ref_count} {}

  constexpr uint64_t ref() {
    uint64_t old_ref_count = ref_count;
    ref_count++;
    return old_ref_count;
  }

  [[nodiscard]] constexpr uint64_t unref() {
    uint64_t old_ref_count = ref_count;
    ref_count--;
    return old_ref_count;
  }
};

struct MultiThreadedRefCount {
  STX_MAKE_PINNED(MultiThreadedRefCount)

  std::atomic<uint64_t> ref_count;

  explicit MultiThreadedRefCount(uint64_t initial_ref_count)
      : ref_count{initial_ref_count} {}

  uint64_t ref() { return ref_count.fetch_add(1, std::memory_order_relaxed); }

  [[nodiscard]] uint64_t unref() {
    return ref_count.fetch_sub(1, std::memory_order_acquire);
  }
};

#if !STX_SINGLE_THREADED
using RefCount = MultiThreadedRefCount;
#else
using RefCount = SingleThreadedRefCount;
#endif